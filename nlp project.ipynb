{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05df208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi! How can I assist you today? (Type 'exit' to end the conversation)\n",
      "You: exit\n",
      "Chatbot: It was great chatting with you! Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Downloading necessary data for NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer to reduce words to their base form\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Predefined text that the chatbot uses to interact\n",
    "chatbot_corpus = \"\"\"\n",
    "Hey there! I am here to assist you with various queries. You can ask me about general information, help with tasks, or just chat!\n",
    "Feel free to ask anything or share what you're working on, and I'll be happy to help!\n",
    "\"\"\"\n",
    "\n",
    "# Helper function to clean and preprocess the text\n",
    "def clean_input(text):\n",
    "    text = text.lower()  # Normalize to lowercase\n",
    "    tokens = nltk.word_tokenize(text)  # Tokenize the input\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in string.punctuation]  # Remove punctuation, lemmatize\n",
    "    return cleaned_tokens\n",
    "\n",
    "# Function to generate a chatbot response based on the input\n",
    "def generate_response(user_input):\n",
    "    user_input_cleaned = clean_input(user_input)\n",
    "    input_vector = tfidf_vectorizer.transform([' '.join(user_input_cleaned)]).toarray()  # Transform input to vector\n",
    "    \n",
    "    # Calculate similarity between the input and the chatbot's predefined responses\n",
    "    similarity_scores = cosine_similarity(input_vector, corpus_vectors)\n",
    "    best_match_idx = np.argmax(similarity_scores)\n",
    "    \n",
    "    # If the similarity score passes a certain threshold, return the closest matching response\n",
    "    if similarity_scores[0][best_match_idx] > 0.4:  # Set the threshold to 0.4\n",
    "        return response_corpus[best_match_idx]\n",
    "    else:\n",
    "        return \"Hmm, I'm not quite sure I understand. Could you rephrase that?\"\n",
    "\n",
    "# Breaking down the corpus into sentences\n",
    "response_corpus = nltk.sent_tokenize(chatbot_corpus)\n",
    "\n",
    "# Vectorizing the sentences using TF-IDF to give weight to relevant words\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "corpus_vectors = tfidf_vectorizer.fit_transform(response_corpus).toarray()\n",
    "\n",
    "# Main loop to run the chatbot interaction\n",
    "def chatbot():\n",
    "    print(\"Chatbot: Hi! How can I assist you today? (Type 'exit' to end the conversation)\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Chatbot: It was great chatting with you! Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            response = generate_response(user_input)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "\n",
    "# Start the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819811a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
